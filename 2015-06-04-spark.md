---
title: spark
date: 2015-06-04
tags: spark, hadoop
---


スループット重視 : Hadoop
レスポンス重視 : Spark

# mac install

```
brew install scala
brew install apache-spark

# spark home - bash
export SPARK_HOME=/usr/local/Cellar/apache-spark/1.6.1/libexec

# spark home - fish
set -x SPARK_HOME /usr/local/Cellar/apache-spark/1.6.1/libexec
```
# 実行方法

<http://www.task-notes.com/entry/20160103/1451810637>

syntax

```
$ ${SPARK_HOME}/bin/spark-submit \
  --master <master-url> \
  --class <main-class>
  --name <name>
  ... # other options
  <application-jar> \
  [application-arguments]
```

example

```
$ mvn package
$ spark-submit \
  --master local \
  --class com.example.spark.SimpleApp \
  target/simple-project-1.0.jar \
  /usr/local/Cellar/apache-spark/1.5.2
...
Lines with a: 60, Lines with b: 29
```

# trouble shooting

## Can't assign requested address

```
16/07/21 10:21:43 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.net.ConnectException: Can't assign requested address
	at java.net.PlainSocketImpl.socketConnect(Native Method)
```

の場合には以下をセット

```
export SPARK_MASTER_IP=127.0.0.1
export SPARK_LOCAL_IP=127.0.0.1
```
